{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed packages\n",
    "import sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take in the data \n",
    "df_raw = pd.read_csv('./anomaly_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating consistent output for random seeds \n",
    "rng = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give the date a datetime data type\n",
    "df_raw['Door Access DateTime'] = pd.to_datetime(df_raw['Door Access DateTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create features for future use \n",
    "\n",
    "df_features = df_raw.copy(deep=True)\n",
    "\n",
    "df_features['Month'] = df_features['Door Access DateTime'].dt.month \n",
    "df_features['Day'] = df_features['Door Access DateTime'].dt.day\n",
    "df_features['MonthDay'] = df_features['Month'].map(str)+ \"/\" + df_features['Day'].map(str)\n",
    "df_features['Hour'] = df_features['Door Access DateTime'].dt.hour\n",
    "df_features['DayofWeek'] = df_raw['Door Access DateTime'].dt.dayofweek\n",
    "df_features['Minute'] = df_features['Door Access DateTime'].dt.minute\n",
    "\n",
    "#get the first and last time there was a login or out for the day\n",
    "df_startend = df_features.groupby(['MonthDay', 'Person Id']).agg(['min', 'max'])['Door Access DateTime'].reset_index()\n",
    "df_features = pd.merge(df_features, df_startend , on = ['MonthDay', 'Person Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a normalized dataset for clustering purposes\n",
    "#chose to drop person ID but alternative would be to use person level information as part of the clustering\n",
    "#but at scale, this would produce a very wide dataframe so decided not to \n",
    "df_cluster = df_features.drop(['MonthDay', 'min', 'max', 'Person Id',  'Door Access DateTime'], axis=1).copy(deep=True)\n",
    "df_cluster = pd.merge(df_cluster, pd.get_dummies(df_cluster.DayofWeek), left_index = True, right_index=True)\n",
    "df_cluster = df_cluster.drop(['DayofWeek'], axis=1)\n",
    "X = StandardScaler().fit_transform(df_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User IDs tend to be sequential so print an error message if the digits are non-consecutive\n",
    "#This may warrant additional follow-up with the data owner or could be fine (such as our test data case)\n",
    "missing_IDs = (df_raw['Person Id'].nunique() - (df_raw['Person Id'].max() - df_raw['Person Id'].min()+1))\n",
    "if missing_IDs != 0:\n",
    "    print('If the userIDs passed were consecutive, we would espect to see ' + str(missing_IDs) + ' more/fewer than we see here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rogue (df_raw, min_visit):\n",
    "    \"\"\"Returns a list of people who have come less than a minimum number of times.\"\"\"\n",
    "    rogue = pd.DataFrame\n",
    "    rogue = pd.DataFrame(df_raw['Person Id'].value_counts()<10)\n",
    "    rogue = rogue[rogue['Person Id']==True]\n",
    "    return rogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def badadmin(df_features, multiple):\n",
    "    \"\"\"Looks for observations that seem like they could have been generated by an admin because the minutes\n",
    "    are disproportionately 'easy' ones like 0, 15, 30, or 45 for a particular person\"\"\"\n",
    "    pct_0 = pd.DataFrame()\n",
    "    pct_0 = df_features[df_features['Minute'].isin(['0','15','30','45'])].groupby('Person Id').count()/df_features.groupby('Person Id').count()\n",
    "    pct_0 = pct_0[pct_0.iloc[:,0]>(4*multiple)/60]\n",
    "    return pct_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flags the entire day as strange if either you come to work before 7 or leave after 8\n",
    "def extreme_timestamp(df_features, min_quantile, max_quantile):\n",
    "    \"\"\"Returns a list of people who have come extremely early or late.\"\"\"\n",
    "    extremes = pd.DataFrame()\n",
    "    early = df_features['Door Access DateTime'].dt.hour.quantile(min_quantile)\n",
    "    late = df_features['Door Access DateTime'].dt.hour.quantile(max_quantile)\n",
    "    extremes = df_features[(df_features['min'].dt.hour<early) | (df_features['max'].dt.hour>late)]\n",
    "    return extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghost_town(df_features, multiple):\n",
    "    ghost_town = pd.DataFrame()\n",
    "    \"\"\"Returns a list of people who come when very few other people are in the office\n",
    "    with the date they came as the index.\"\"\"\n",
    "    daily_attendance = df_features.groupby('MonthDay').count()['Person Id']\n",
    "    df_attendance = pd.DataFrame(daily_attendance)\n",
    "    df_attendance = pd.merge(df_attendance,df_features, left_index=True, right_on='MonthDay') \n",
    "    cutoff = df_attendance['Person Id_x'].mean()/10\n",
    "    ghost_town = df_attendance[df_attendance['Person Id_x']<cutoff]\n",
    "    return ghost_town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_swipe(df_features, multiple):\n",
    "    \"\"\"Returns a list of people who have days with odd numbers of swipes more than X\n",
    "    multiple times the average among missed swipers\"\"\"\n",
    "    df_miss = pd.DataFrame()\n",
    "    final = []\n",
    "    missed_swipe = df_features.groupby(['MonthDay', 'Person Id']).count()['Door Access DateTime']%2\n",
    "    missed_swipe = missed_swipe[missed_swipe>0]\n",
    "    miss_list = missed_swipe.groupby('Person Id').sum()\n",
    "    miss_list = miss_list[miss_list>(multiple*miss_list.mean())]\n",
    "    missing = pd.DataFrame(miss_list).index[0]\n",
    "    final.append(missing)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(X, skCluster, pct):\n",
    "    \"\"\"Iterates through clustering methods and returns a list of odd timestamps\"\"\"\n",
    "    cluster_outlier = []\n",
    "    for method in skCluster:\n",
    "        clf = method.fit(X)\n",
    "        labels = clf.labels_\n",
    "        labels_unique = np.unique(labels)\n",
    "        n_clusters_ = len(labels_unique)\n",
    "        for i in labels_unique:\n",
    "            if np.where(clf.labels_ == i)[0].shape[0] < X.shape[0]*pct:\n",
    "                cluster_outlier = set(list(cluster_outlier)) | set(list(np.where(clf.labels_ == i)[0]))\n",
    "    return cluster_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_forest(X, IForest):\n",
    "    iforest_outlier = []\n",
    "    IForest.fit( X)\n",
    "    I_Pred = IForest.predict(X)\n",
    "    df_ipred = pd.DataFrame(I_Pred, columns={'Outlier'})\n",
    "    iforest_outlier = set(df_ipred[df_ipred['Outlier']==-1].index) | set(iforest_outlier)\n",
    "    return iforest_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make final dataframe\n",
    "df_final = df_raw.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final function calls at the end of the script\n",
    "#rules based methods\n",
    "#return individual persons rather than swipes in/out\n",
    "rogue_obs = rogue(df_raw, min_visit = 10)\n",
    "non_swipers = missed_swipe(df_features, multiple = 1)\n",
    "\n",
    "#compiled list of individually suspicious people  \n",
    "bad_actors = set(rogue_obs.values.tolist()) | set(non_swipers)\n",
    "\n",
    "#returns a list of timestamps \n",
    "extremes = extreme_timestamp(df_features, min_quantile =.005, max_quantile=.995)\n",
    "badadmin = badadmin(df_features, 4)\n",
    "ghosts = ghost_town(df_features, multiple = 10)\n",
    "\n",
    "#adding to final dataframe\n",
    "df_final['Extreme'] = df_final.index.isin(extremes.index)*1\n",
    "df_final['badadmin'] = df_final.index.isin(badadmin.index)*1\n",
    "df_final['ghosts'] = df_final.index.isin(ghosts.index)*1\n",
    "\n",
    "#compiled list of worrisome swipes in/out of the building \n",
    "worrisome_swipes = set(list(extremes.index)) | set(list(badadmin.index)) | set(list(ghosts.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusering methods\n",
    "brc = Birch(branching_factor=50, n_clusters=None, threshold=1.5,compute_labels=True)\n",
    "db = DBSCAN(eps=.3, min_samples=2)\n",
    "\n",
    "skCluster = { db, brc}\n",
    "cluster_picks = cluster(X, skCluster, pct=.001)\n",
    "\n",
    "df_final['cluster_pick'] = df_final.index.isin(cluster_picks)*1\n",
    "\n",
    "IForest = IsolationForest( contamination=.001, random_state =rng)\n",
    "forest_pick = outlier_forest(X, IForest)\n",
    "\n",
    "df_final['forest_pick'] = df_final.index.isin(forest_pick)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one liner for local outlier detection so a function is gratiutous here\n",
    "X_outliers  = LocalOutlierFactor(n_neighbors=100, contamination =.001)\n",
    "df_outlier = pd.DataFrame(X_outliers.fit_predict(X), columns={'Local Outlier'}) \n",
    "\n",
    "neighbor_pick = df_outlier[df_outlier['Local Outlier']==-1].shape\n",
    "\n",
    "df_final['neighbor_pick'] = df_final.index.isin(neighbor_pick)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all of the results of the functions to get good stuff\n",
    "ml_picks = set(forest_pick) | set(neighbor_pick) | set(cluster_picks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 uniquely anomalous swipes detected. CSVs written to this folder with full history and reasons.\n"
     ]
    }
   ],
   "source": [
    "all_anomaly = set(ml_picks) | set(worrisome_swipes)\n",
    "print(str(len(all_anomaly)) + ' uniquely anomalous swipes detected. CSVs written to this folder with full history and reasons.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create total flags for prioritization \n",
    "df_final['Number of Flags'] = df_final.iloc[:,2:8].sum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writes questionable timestamp of swipes to CSV sorted by descending number of flags\n",
    "df_final.loc[all_anomaly].sort_values(by = 'Number of Flags', ascending=False).to_csv('anomalous_swipes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writes potentially, but not necessarily, overlapping list of bad actors\n",
    "#list to CSV that focuses on person-level behavior rather than their individual\n",
    "#swipes\n",
    "df_bad = pd.DataFrame(np.array(list((bad_actors))))\n",
    "df_bad.to_csv('potential_bad_actors.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
